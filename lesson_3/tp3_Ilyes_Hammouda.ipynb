{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST with an MLP, from scratch\n",
    "\n",
    "# - Step 1: build an MLP from scratch to solve MNIST. Question set: https://fleuret.org/dlc/materials/dlc-practical-3.pdf\n",
    "# - Step 2: debug your network with backprop ninja and a reference implementation using torch's .backward()\n",
    "# - Step 3: build the same MLP but will full pytorch code (nn.Linear, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9489668e20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input[4].view((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (preds, targets):\n",
    "    \"\"\" Computes the accuracy between predictions and targets. Data is expected to be one-hot encoded. \"\"\"\n",
    "    _, idx1 = torch.max(preds, dim=1)\n",
    "    _, idx2 = torch.max(targets, dim=1)\n",
    "    d = idx1 == idx2\n",
    "    return d.int().float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "# this cell should return 0.75\n",
    "preds = torch.zeros((4,7))\n",
    "preds[0,1] = 1\n",
    "preds[1,4] = 1\n",
    "preds[2,2] = 1\n",
    "preds[3,6] = 1\n",
    "targets = torch.zeros((4,7))\n",
    "targets[0,1] = 1\n",
    "targets[1,4] = 1\n",
    "targets[2,2] = 1\n",
    "targets[3,2] = 1\n",
    "compute_accuracy(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def dsigma(x):\n",
    "    return 1 - torch.pow(sigma(x), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss (v,t):\n",
    "    return(torch.sum (torch.pow(v-t,2)))\n",
    "\n",
    "def dloss(v,t):\n",
    "    return torch.mul(2, (v-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1356, -0.0373,  2.5635, -0.3601,  1.0764,  0.6171],\n",
       "        [ 2.4355,  0.2436,  2.4944,  1.1067, -1.4013, -0.7925],\n",
       "        [ 2.6075, -5.9662,  6.2123, -3.6598,  4.7771,  4.0356]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "v = torch.randn((3, 6), dtype=torch.float32)\n",
    "t = torch.randn((3, 6), dtype=torch.float32)\n",
    "l=loss(v,t)\n",
    "dloss(v,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply targets by 0.9 to be in the range of tanh\n",
    "train_target *= 0.9\n",
    "test_target *= 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "# DO NOT MODIFY IT\n",
    "#\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "w1 = torch.ones((784, 50), requires_grad=True)\n",
    "b1 = torch.ones((50), requires_grad=True)\n",
    "w2 = torch.ones((50, 10), requires_grad=True)\n",
    "b2 = torch.ones((10), requires_grad=True)\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]), tensor(55.8500, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = train_input[:5]\n",
    "y1 = train_target[:5]\n",
    "z1 = x1 @ w1 + b1.t()\n",
    "h1 = sigma(z1)\n",
    "z2 = h1 @ w2 + b2.t()\n",
    "h2 = sigma(z2)\n",
    "l = loss(h2, y1)\n",
    "h2.shape, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=55.849998474121094\n"
     ]
    }
   ],
   "source": [
    "# Force pytorch to retain grade for intermediate nodes and reset grad for parameters\n",
    "# DO NOT MODIFY THIS CODE\n",
    "#\n",
    "others = [h2,z2,h1,z1]\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in others:\n",
    "    t.retain_grad()\n",
    "l.backward()\n",
    "print(f'loss={l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "z2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "w2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "z1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "w1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# here we compare our gradient to the reference gradient computed by pytorch\n",
    "dl = 1.0\n",
    "dh2 = dloss(h2, y1)\n",
    "cmp('h2',dh2,h2)\n",
    "dz2 = torch.mul(dh2, dsigma(z2))\n",
    "cmp('z2',dz2, z2)\n",
    "dw2 = h1.t() @ dz2\n",
    "cmp('w2',dw2, w2)\n",
    "db2 = dz2.sum(0).reshape(b2.shape)\n",
    "cmp('b2',db2, b2)\n",
    "dh1 = dz2 @ w2.t()\n",
    "cmp('h1',dh1, h1)\n",
    "dz1 = torch.mul(dh1, dsigma(z1))\n",
    "cmp('z1', dz1, z1)\n",
    "dw1 = x1.t() @ dz1\n",
    "cmp('w1', dw1, w1)\n",
    "db1 = dz1.sum(0).reshape(b1.shape)\n",
    "cmp('b1', db1, b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    w1 += -lr * dw1\n",
    "    #print(f'b1:{b1.shape}, \\n db1:{db1.squeeze().shape}')\n",
    "    b1 += -lr * db1.squeeze()\n",
    "    w2 += -lr * dw2\n",
    "    b2 += -lr * db2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.849998474121094"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = loss(h2, y1)\n",
    "l.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that we've checked our gradients are correct, we can implement the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w1, b1, w2, b2, x):\n",
    "    z1 = x @ w1 + b1.t()\n",
    "    h1 = sigma(z1)\n",
    "    z2 = h1 @ w2 + b2.t()\n",
    "    h2 = sigma(z2)\n",
    "    return z1, h1, z2, h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(w1, b1, w2, b2, x1, y1, h2, z2, h1, z1):\n",
    "    dl = 1.0\n",
    "    dh2 = dloss(h2, y1)\n",
    "    dz2 = torch.mul(dh2, dsigma(z2))\n",
    "    dw2 = h1.t() @ dz2\n",
    "    db2 = dz2.sum(0).reshape(b2.shape)\n",
    "    dh1 = dz2 @ w2.t()\n",
    "    dz1 = torch.mul(dh1, dsigma(z1))\n",
    "    dw1 = x1.t() @ dz1\n",
    "    db1 = dz1.sum(0).reshape(b1.shape)\n",
    "        \n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    with torch.no_grad():\n",
    "        w1 += -lr * dw1\n",
    "        b1 +=  -lr * db1.squeeze()\n",
    "        w2 += -lr * dw2\n",
    "        b2 += -lr * db2.squeeze()\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \"\"\" init a network \"\"\"\n",
    "    torch.manual_seed(1337)\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main training loop\n",
    "torch.set_printoptions(linewidth=200)\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        lsi = loss(h2, yb)\n",
    "        # backward\n",
    "        dw1, db1, dw2, db2 = backward(w1, b1, w2, b2, xb, yb, h2, z2, h1, z1)\n",
    "        # update\n",
    "        lr = 0.1 / num_samples if step < 5000 else 0.01 / num_samples\n",
    "        w1, b1, w2, b2 = update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr)\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 10828.0\n",
      "step = 100, loss = 10828.0\n",
      "step = 200, loss = 10828.0\n",
      "step = 300, loss = 10828.0\n",
      "step = 400, loss = 10828.0\n",
      "step = 500, loss = 10828.0\n",
      "step = 600, loss = 10828.0\n",
      "step = 700, loss = 10828.0\n",
      "step = 800, loss = 10828.0\n",
      "step = 900, loss = 10828.0\n",
      "step = 1000, loss = 10828.0\n",
      "step = 1100, loss = 10828.0\n",
      "step = 1200, loss = 10828.0\n",
      "step = 1300, loss = 10828.0\n",
      "step = 1400, loss = 10828.0\n",
      "step = 1500, loss = 10828.0\n",
      "step = 1600, loss = 10828.0\n",
      "step = 1700, loss = 10828.0\n",
      "step = 1800, loss = 10828.0\n",
      "step = 1900, loss = 10828.0\n",
      "step = 2000, loss = 10828.0\n",
      "step = 2100, loss = 10828.0\n",
      "step = 2200, loss = 10828.0\n",
      "step = 2300, loss = 10828.0\n",
      "step = 2400, loss = 10828.0\n",
      "step = 2500, loss = 10828.0\n",
      "step = 2600, loss = 10828.0\n",
      "step = 2700, loss = 10828.0\n",
      "step = 2800, loss = 10828.0\n",
      "step = 2900, loss = 10828.0\n",
      "step = 3000, loss = 10828.0\n",
      "step = 3100, loss = 10828.0\n",
      "step = 3200, loss = 10828.0\n",
      "step = 3300, loss = 10828.0\n",
      "step = 3400, loss = 10828.0\n",
      "step = 3500, loss = 10828.0\n",
      "step = 3600, loss = 10828.0\n",
      "step = 3700, loss = 10828.0\n",
      "step = 3800, loss = 10828.0\n",
      "step = 3900, loss = 10828.0\n",
      "step = 4000, loss = 10828.0\n",
      "step = 4100, loss = 10828.0\n",
      "step = 4200, loss = 10828.0\n",
      "step = 4300, loss = 10828.0\n",
      "step = 4400, loss = 10828.0\n",
      "step = 4500, loss = 10828.0\n",
      "step = 4600, loss = 10828.0\n",
      "step = 4700, loss = 10828.0\n",
      "step = 4800, loss = 10828.0\n",
      "step = 4900, loss = 10828.0\n",
      "step = 5000, loss = 10828.0\n",
      "step = 5100, loss = 10828.0\n",
      "step = 5200, loss = 10828.0\n",
      "step = 5300, loss = 10828.0\n",
      "step = 5400, loss = 10828.0\n",
      "step = 5500, loss = 10828.0\n",
      "step = 5600, loss = 10828.0\n",
      "step = 5700, loss = 10828.0\n",
      "step = 5800, loss = 10828.0\n",
      "step = 5900, loss = 10828.0\n",
      "step = 6000, loss = 10828.0\n",
      "step = 6100, loss = 10828.0\n",
      "step = 6200, loss = 10828.0\n",
      "step = 6300, loss = 10828.0\n",
      "step = 6400, loss = 10828.0\n",
      "step = 6500, loss = 10828.0\n",
      "step = 6600, loss = 10828.0\n",
      "step = 6700, loss = 10828.0\n",
      "step = 6800, loss = 10828.0\n",
      "step = 6900, loss = 10828.0\n",
      "step = 7000, loss = 10828.0\n",
      "step = 7100, loss = 10828.0\n",
      "step = 7200, loss = 10828.0\n",
      "step = 7300, loss = 10828.0\n",
      "step = 7400, loss = 10828.0\n",
      "step = 7500, loss = 10828.0\n",
      "step = 7600, loss = 10828.0\n",
      "step = 7700, loss = 10828.0\n",
      "step = 7800, loss = 10828.0\n",
      "step = 7900, loss = 10828.0\n",
      "step = 8000, loss = 10828.0\n",
      "step = 8100, loss = 10828.0\n",
      "step = 8200, loss = 10828.0\n",
      "step = 8300, loss = 10828.0\n",
      "step = 8400, loss = 10828.0\n",
      "step = 8500, loss = 10828.0\n",
      "step = 8600, loss = 10828.0\n",
      "step = 8700, loss = 10828.0\n",
      "step = 8800, loss = 10828.0\n",
      "step = 8900, loss = 10828.0\n",
      "step = 9000, loss = 10828.0\n",
      "step = 9100, loss = 10828.0\n",
      "step = 9200, loss = 10828.0\n",
      "step = 9300, loss = 10828.0\n",
      "step = 9400, loss = 10828.0\n",
      "step = 9500, loss = 10828.0\n",
      "step = 9600, loss = 10828.0\n",
      "step = 9700, loss = 10828.0\n",
      "step = 9800, loss = 10828.0\n",
      "step = 9900, loss = 10828.0\n",
      "train_accuracy=0.09700000286102295\n",
      "test_accuracy=0.08500000089406967\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f946a993bb0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)\n",
    "#print(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reference implementation using pytorch's .backward()\n",
    "Nothing to do in Step 2, this code is provided for you as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import torch.nn as F\n",
    "\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        xloss = F.MSELoss()\n",
    "        lsi = xloss(h2, yb) * yb.nelement()\n",
    "        # backward\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        lsi.backward()\n",
    "        # update\n",
    "        lr = 0.1 / num_samples\n",
    "        for p in parameters:\n",
    "            p.data += -lr * p.grad\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = train(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the same MLP layer but with fully pytorch code (nn.Linear(), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network dimensions\n",
    "n_in = 784\n",
    "n_hidden = 200\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_tr = train_input, train_target\n",
    "X_test, Y_test = test_input, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            ???\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        ???\n",
    "    \n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters]\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "    optimizer.???\n",
    "    loss.backward()\n",
    "    optimizer.???\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            # train accuracy\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            # test accuracy\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise: try to improve accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
